{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = datasets.load_files(r\"20_newsgroups\")\n",
    "x = text_data.data\n",
    "y = text_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x),type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19997 19997\n"
     ]
    }
   ],
   "source": [
    "print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the training data using regex library of python\n",
    "X = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    # Removing all the non-word characters ie not present in {a-z, A-Z, 0-9, _}\n",
    "    text = re.sub(r'\\W',' ',str(x[i]))\n",
    "    \n",
    "    # Converting multiple spaces to single blank space\n",
    "    text = re.sub(r'\\s+',' ',text, flags=re.I)\n",
    "    \n",
    "    # Removing the prefixed b from the text\n",
    "    text = re.sub(r'^b\\s+','',text)\n",
    "    \n",
    "    # Removing all the numbers\n",
    "    text = re.sub(r'\\d+','',text)\n",
    "    \n",
    "    # Converting to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    X.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 19997\n"
     ]
    }
   ],
   "source": [
    "print(type(X),len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/divij/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the Stop Words\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "print(len(stop_words))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the initial dictionary of all the unique words and their frequencies\n",
    "dictionary = {}\n",
    "\n",
    "for i in X:\n",
    "    for word in i.split():\n",
    "        if word not in stop_words:\n",
    "            dictionary[word] = dictionary.get(word,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164593\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting a line graph for the number of words vs the frequencies\n",
    "temp = {}\n",
    "for i in dictionary:\n",
    "    temp[dictionary[i]] = temp.get(dictionary[i],0) + 1\n",
    "\n",
    "x_axis = []\n",
    "y_axis = []\n",
    "for i in sorted(temp.keys()):\n",
    "    y_axis.append(i)\n",
    "    x_axis.append(temp[i])\n",
    "plt.plot(x_axis,y_axis)\n",
    "plt.xlabel(\"Number of words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title('Number of words vs their frequencies')\n",
    "plt.axis([0,10000,1,150])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5078\n"
     ]
    }
   ],
   "source": [
    "# Selecting a cutoff freq ie discarding the words having a freq below the cutoff\n",
    "cutoff = 120\n",
    "final_dict = {}\n",
    "for i in dictionary:\n",
    "    if dictionary[i] >= cutoff:\n",
    "        final_dict[i] = dictionary[i]\n",
    "print(len(final_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19997, 5078)\n"
     ]
    }
   ],
   "source": [
    "# Building a 2D np array of the words and their frequencies\n",
    "words = list(final_dict.keys())\n",
    "X_array = np.zeros((len(X),len(final_dict)))\n",
    "\n",
    "for i in range(len(X)):\n",
    "    curr_doc = X[i].split()\n",
    "    for word in curr_doc:\n",
    "        if word in words:\n",
    "            j = words.index(word)\n",
    "            X_array[i][j] += 1\n",
    "print(X_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 2., ..., 0., 0., 0.],\n",
       "       [0., 2., 3., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_array\n",
    "Y_train = y\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a fit function which makes a result dictionary containing frequencies of words for each class present in Y\n",
    "def fit(X_train,Y_train):\n",
    "    result = {}\n",
    "    classes = set(Y_train)\n",
    "    result['total_rows'] = len(Y_train)\n",
    "    for curr_class in classes:\n",
    "        result[curr_class] = {}\n",
    "        class_total = 0\n",
    "        X_class = X_train[Y_train == curr_class]\n",
    "        Y_class = Y_train[Y_train == curr_class]\n",
    "        num_features = X_train.shape[1]\n",
    "        result[curr_class]['total_class_rows'] = len(Y_class)\n",
    "        for j in range(num_features):\n",
    "            result[curr_class][j] = X_class[:,j].sum()\n",
    "            class_total += result[curr_class][j]\n",
    "        result[curr_class]['total_class_freq'] = class_total\n",
    "    return result\n",
    "    \n",
    "# This function calculates the probability of the given class based on the value of a single datapoint.    \n",
    "def probability(curr_class,result,row):\n",
    "    output = np.log(result[curr_class]['total_class_rows']) - np.log(result['total_rows'])\n",
    "    num_features = len(result[curr_class].keys())-2\n",
    "    for j in range(len(row)):\n",
    "        num = result[curr_class][j]+1\n",
    "        denom = result[curr_class]['total_class_freq'] + len(row)\n",
    "        prob = np.log(num) - np.log(denom)\n",
    "        output += row[j]*prob\n",
    "    return output\n",
    " \n",
    "# This function predicts the best class for a single datapoint. The probabilities of each class are found using the \n",
    "# above function and the class having the maximum probability is returned as the best class.\n",
    "def predictSinglePoint(result, row):\n",
    "    classes = result.keys()\n",
    "    best_class = -1\n",
    "    best_p = -1000\n",
    "    first_run = True\n",
    "    for curr_class in classes:\n",
    "        if curr_class == 'total_data_freq' or curr_class == 'total_rows':\n",
    "            continue\n",
    "        p_current_class = probability(curr_class,result,row)\n",
    "        if first_run or p_current_class > best_p :\n",
    "            best_p = p_current_class\n",
    "            best_class = curr_class\n",
    "            first_run = False\n",
    "    return best_class\n",
    "\n",
    "# A function defined to predict the values of y given the x_test values. The best class for each datapoint is received \n",
    "# from the above function and the classes for each datapoint is added to the y_pred list.\n",
    "def predict(result, X_test):\n",
    "    y_pred = []\n",
    "    for row in X_test:\n",
    "        x_class = predictSinglePoint(result,row)\n",
    "        y_pred.append(x_class)\n",
    "    return y_pred        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_dict = fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading testing data\n",
    "testing_data = datasets.load_files(r\"mini_newsgroups\")\n",
    "x_test = testing_data.data\n",
    "y_test = testing_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the testing data using the regex library\n",
    "X_test = []\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    # Removing all the non-word characters ie not present in {a-z, A-Z, 0-9, _}\n",
    "    text = re.sub(r'\\W',' ',str(x_test[i]))\n",
    "    \n",
    "    # Converting multiple spaces to single blank space\n",
    "    text = re.sub(r'\\s+',' ',text, flags=re.I)\n",
    "    \n",
    "    # Removing the prefixed b from the text\n",
    "    text = re.sub(r'^b\\s+','',text)\n",
    "    \n",
    "    # Removing all the numbers\n",
    "    text = re.sub(r'\\d+','',text)\n",
    "    \n",
    "    # Converting to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    X_test.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 5078)\n"
     ]
    }
   ],
   "source": [
    "# Creating a 2D numpy array for the testing data\n",
    "\n",
    "X_test_array = np.zeros((len(X_test),len(final_dict)))\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    curr_doc = X_test[i].split()\n",
    "    for word in curr_doc:\n",
    "        if word in words:\n",
    "            j = words.index(word)\n",
    "            X_test_array[i][j] += 1\n",
    "print(X_test_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Sklearn's inbuilt Multinomial Naive Bayes\n",
      "\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.82      0.87      0.84       100\n",
      "           comp.graphics       0.77      0.87      0.82       100\n",
      " comp.os.ms-windows.misc       0.89      0.08      0.15       100\n",
      "comp.sys.ibm.pc.hardware       0.53      0.90      0.66       100\n",
      "   comp.sys.mac.hardware       0.86      0.92      0.89       100\n",
      "          comp.windows.x       0.86      0.82      0.84       100\n",
      "            misc.forsale       0.84      0.98      0.91       100\n",
      "               rec.autos       0.98      0.95      0.96       100\n",
      "         rec.motorcycles       0.96      0.97      0.97       100\n",
      "      rec.sport.baseball       0.99      0.97      0.98       100\n",
      "        rec.sport.hockey       0.98      0.94      0.96       100\n",
      "               sci.crypt       0.98      0.96      0.97       100\n",
      "         sci.electronics       0.89      0.93      0.91       100\n",
      "                 sci.med       0.97      0.94      0.95       100\n",
      "               sci.space       0.97      0.95      0.96       100\n",
      "  soc.religion.christian       0.97      0.99      0.98       100\n",
      "      talk.politics.guns       0.85      0.93      0.89       100\n",
      "   talk.politics.mideast       0.97      0.93      0.95       100\n",
      "      talk.politics.misc       0.83      0.74      0.78       100\n",
      "      talk.religion.misc       0.75      0.73      0.74       100\n",
      "\n",
      "                accuracy                           0.87      2000\n",
      "               macro avg       0.88      0.87      0.86      2000\n",
      "            weighted avg       0.88      0.87      0.86      2000\n",
      "\n",
      "[[87  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  2 10]\n",
      " [ 0 87  0  3  2  3  2  0  0  0  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0 14  8 64  1  8  3  0  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 1  1  0 90  5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  6 92  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  6  0  5  3 82  1  0  0  0  0  1  0  1  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 98  1  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  1 95  0  0  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  1 97  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0 97  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  1  1 94  0  0  1  1  0  0  0  1  0]\n",
      " [ 0  1  0  0  1  0  1  0  0  0  0 96  0  1  0  0  0  0  0  0]\n",
      " [ 0  1  0  2  1  0  2  0  0  0  0  0 93  0  1  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  2  0  0  0  2 94  0  0  0  0  1  0]\n",
      " [ 0  2  0  0  1  2  0  0  0  0  0  0  0  0 95  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0 99  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0 93  0  3  2]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  1 93  5  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  3 74 12]\n",
      " [18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  4  0  3 73]]\n"
     ]
    }
   ],
   "source": [
    "# Using the inbuilt Multinomial NB\n",
    "cif = MultinomialNB()\n",
    "cif.fit(X_train,Y_train)\n",
    "y_pred_inbuilt = cif.predict(X_test_array)\n",
    "\n",
    "# Since y_pred has predictions in the form of numbers, they need to be converted to names\n",
    "class_names = text_data.target_names\n",
    "\n",
    "y_test_named = []\n",
    "for i in y_test:\n",
    "    y_test_named.append(class_names[i])\n",
    "    \n",
    "y_pred_named_inbuilt = []\n",
    "for i in y_pred_inbuilt:\n",
    "    y_pred_named_inbuilt.append(class_names[i])\n",
    "\n",
    "print(\"Using Sklearn's inbuilt Multinomial Naive Bayes\")\n",
    "print()\n",
    "print(classification_report(y_test_named,y_pred_named_inbuilt))\n",
    "print(confusion_matrix(y_test_named,y_pred_named_inbuilt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Multinomial Naive Bayes written from scratch\n",
      "\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.82      0.87      0.84       100\n",
      "           comp.graphics       0.77      0.87      0.82       100\n",
      " comp.os.ms-windows.misc       0.89      0.08      0.15       100\n",
      "comp.sys.ibm.pc.hardware       0.53      0.90      0.66       100\n",
      "   comp.sys.mac.hardware       0.86      0.92      0.89       100\n",
      "          comp.windows.x       0.86      0.82      0.84       100\n",
      "            misc.forsale       0.84      0.98      0.91       100\n",
      "               rec.autos       0.98      0.95      0.96       100\n",
      "         rec.motorcycles       0.96      0.97      0.97       100\n",
      "      rec.sport.baseball       0.99      0.97      0.98       100\n",
      "        rec.sport.hockey       0.98      0.94      0.96       100\n",
      "               sci.crypt       0.98      0.96      0.97       100\n",
      "         sci.electronics       0.89      0.93      0.91       100\n",
      "                 sci.med       0.97      0.94      0.95       100\n",
      "               sci.space       0.97      0.95      0.96       100\n",
      "  soc.religion.christian       0.97      0.99      0.98       100\n",
      "      talk.politics.guns       0.85      0.93      0.89       100\n",
      "   talk.politics.mideast       0.97      0.93      0.95       100\n",
      "      talk.politics.misc       0.83      0.74      0.78       100\n",
      "      talk.religion.misc       0.75      0.73      0.74       100\n",
      "\n",
      "                accuracy                           0.87      2000\n",
      "               macro avg       0.88      0.87      0.86      2000\n",
      "            weighted avg       0.88      0.87      0.86      2000\n",
      "\n",
      "[[87  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  2 10]\n",
      " [ 0 87  0  3  2  3  2  0  0  0  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0 14  8 64  1  8  3  0  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 1  1  0 90  5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  6 92  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  6  0  5  3 82  1  0  0  0  0  1  0  1  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 98  1  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  1 95  0  0  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  1 97  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0 97  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  1  1 94  0  0  1  1  0  0  0  1  0]\n",
      " [ 0  1  0  0  1  0  1  0  0  0  0 96  0  1  0  0  0  0  0  0]\n",
      " [ 0  1  0  2  1  0  2  0  0  0  0  0 93  0  1  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  2  0  0  0  2 94  0  0  0  0  1  0]\n",
      " [ 0  2  0  0  1  2  0  0  0  0  0  0  0  0 95  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0 99  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0 93  0  3  2]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  1 93  5  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  3 74 12]\n",
      " [18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  4  0  3 73]]\n"
     ]
    }
   ],
   "source": [
    "# Using the MultiNomial Naive Bayes written from scratch\n",
    "y_pred_scratch = predict(trained_dict,X_test_array)\n",
    "\n",
    "# Creating named y_pred\n",
    "y_pred_named_scratch = []\n",
    "for i in y_pred_scratch:\n",
    "    y_pred_named_scratch.append(class_names[i])\n",
    "\n",
    "print(\"Using Multinomial Naive Bayes written from scratch\")\n",
    "print()\n",
    "print(classification_report(y_test_named,y_pred_named_scratch))\n",
    "print(confusion_matrix(y_test_named,y_pred_named_scratch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between the results of the inbuilt function and the function built from scratch are in: 0 values\n",
      "Since there is no difference in any of the predicted values for the testing data, it can be concluded that the Multinomial NB built from scratch is as good as the inbuilt one.\n"
     ]
    }
   ],
   "source": [
    "# In order to check how the results provided by my function compare to those provided by the inbuilt function\n",
    "# I am running a loop over both y_pred and printing the values if the result differs\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_pred_named_inbuilt)):\n",
    "    if y_pred_named_inbuilt[i] != y_pred_named_scratch[i]:\n",
    "        count += 1\n",
    "print(\"The difference between the results of the inbuilt function and the function built from scratch are in:\",count\n",
    "     ,\"values\")\n",
    "if count == 0:\n",
    "    print(\"Since there is no difference in any of the predicted values for the testing data, it can be concluded that the Multinomial NB built from scratch is as good as the inbuilt one.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
